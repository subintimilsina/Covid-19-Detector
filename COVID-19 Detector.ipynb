{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"Dataset/Train\"\n",
    "VAL_PATH = \"Dataset/validations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(ni, size=3,stride=1):\n",
    "    for_pad = lambda s: s if s > 2 else 3\n",
    "    return Sequential(\n",
    "        [\n",
    "        Conv2D(ni, kernel_size=size, padding=\"same\",use_bias=False), \n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1)  \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_conv(ni,nf):\n",
    "    return Sequential(\n",
    "        [\n",
    "        conv_block(nf),\n",
    "        conv_block(ni,size=1),  \n",
    "        conv_block(nf)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling():\n",
    "    return MaxPooling2D(2, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inital():\n",
    "    return Sequential(\n",
    "        [\n",
    "        Conv2D(8,kernel_size=(3,3),padding=\"same\",input_shape=(224,224,3)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1)  \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cdd170825ad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#CNN based model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model = Sequential(\n\u001b[0m\u001b[0;32m      4\u001b[0m     [\n\u001b[0;32m      5\u001b[0m     \u001b[0minital\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#CNN based model\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "    inital(), \n",
    "    maxpooling(),\n",
    "    conv_block(16),\n",
    "    maxpooling(),\n",
    "    triple_conv(16,32),\n",
    "    maxpooling(),\n",
    "    triple_conv(32,64),\n",
    "    maxpooling(),\n",
    "    triple_conv(64,128),\n",
    "    maxpooling(),\n",
    "    triple_conv(128,256),\n",
    "    conv_block(128,size=1),\n",
    "    conv_block(256),\n",
    "    Flatten(),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=Adam(lr=0.0005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_182 (Conv2D)          (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "sequential_219 (Sequential)  (None, 112, 112, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "sequential_223 (Sequential)  (None, 56, 56, 32)        10048     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "sequential_227 (Sequential)  (None, 28, 28, 64)        39552     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "sequential_231 (Sequential)  (None, 14, 14, 128)       156928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "sequential_235 (Sequential)  (None, 7, 7, 256)         625152    \n",
      "_________________________________________________________________\n",
      "sequential_236 (Sequential)  (None, 7, 7, 128)         33280     \n",
      "_________________________________________________________________\n",
      "sequential_237 (Sequential)  (None, 7, 7, 256)         295936    \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               3211520   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 4,374,113\n",
      "Trainable params: 4,370,913\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    ")\n",
    "\n",
    "test_dataset = image.ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data.flow_from_directory(\n",
    "    'Dataset/Train',\n",
    "    target_size = (224,224),\n",
    "    batch_size= 32,\n",
    "    class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID': 0, 'Normal': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_dataset.flow_from_directory(\n",
    "    'Dataset/validations',\n",
    "    target_size = (224,224),\n",
    "    batch_size= 32,\n",
    "    class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6960 - accuracy: 0.7667 - val_loss: 0.7068 - val_accuracy: 0.4844\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.2055 - accuracy: 0.9625 - val_loss: 0.7604 - val_accuracy: 0.4844\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1866 - accuracy: 0.9458 - val_loss: 0.8586 - val_accuracy: 0.4688\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0826 - accuracy: 0.9648 - val_loss: 1.2546 - val_accuracy: 0.4688\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1656 - accuracy: 0.9458 - val_loss: 1.8327 - val_accuracy: 0.4844\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1232 - accuracy: 0.9833 - val_loss: 2.6918 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2163 - accuracy: 0.9453 - val_loss: 3.1619 - val_accuracy: 0.4688\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0765 - accuracy: 0.9708 - val_loss: 1.8843 - val_accuracy: 0.5156\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1016 - accuracy: 0.9750 - val_loss: 2.8406 - val_accuracy: 0.4688\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0634 - accuracy: 0.9875 - val_loss: 4.7595 - val_accuracy: 0.4531\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0355 - accuracy: 0.9917 - val_loss: 4.8222 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0212 - accuracy: 0.9961 - val_loss: 5.4405 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 6.4993 - val_accuracy: 0.4688\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0178 - accuracy: 0.9917 - val_loss: 7.0740 - val_accuracy: 0.4688\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 8.1504 - val_accuracy: 0.4375\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0346 - accuracy: 0.9833 - val_loss: 6.8888 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0522 - accuracy: 0.9875 - val_loss: 8.4470 - val_accuracy: 0.4375\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0250 - accuracy: 0.9958 - val_loss: 8.8595 - val_accuracy: 0.4844\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 9.9280 - val_accuracy: 0.4688\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 10.3463 - val_accuracy: 0.4688\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=20,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
